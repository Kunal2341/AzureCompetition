{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "blank-magazine",
   "metadata": {},
   "source": [
    "# Calling the API\n",
    "Done:\n",
    "- tag_image_in_stream\n",
    "- describe_image_in_stream\n",
    "- detect_objects_in_stream\n",
    "- get_area_of_interest_in_stream\n",
    "- analyze_image_in_stream\n",
    "\n",
    "https://docs.microsoft.com/en-us/python/api/azure-cognitiveservices-vision-computervision/azure.cognitiveservices.vision.computervision.operations.computervisionclientoperationsmixin?view=azure-python#analyze-image-in-stream-image--visual-features-none--details-none--language--en---description-exclude-none--custom-headers-none--raw-false--callback-none----operation-config-\n",
    "\n",
    "\n",
    "https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/category-taxonomy\n",
    "\n",
    "\n",
    "https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/concept-object-detection\n",
    "\n",
    "https://docs.microsoft.com/en-us/python/api/azure-cognitiveservices-vision-computervision/azure.cognitiveservices.vision.computervision.operations.computervisionclientoperationsmixin?view=azure-python#analyze-image-by-domain-in-stream-model--image--language--en---custom-headers-none--raw-false--callback-none----operation-config-\n",
    "\n",
    "\n",
    "https://azure.microsoft.com/en-us/services/cognitive-services/computer-vision/#features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "authorized-rouge",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "from array import array\n",
    "import os\n",
    "from PIL import Image\n",
    "import sys\n",
    "import time\n",
    "subscription_key = \"53f32bba50f1443cb9ae7e927441db83\"\n",
    "endpoint = \"https://azurehackforaccessibility.cognitiveservices.azure.com/\"\n",
    "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))\n",
    "local_image_path = \"/Users/kunal/Documents/AzureCompetition/img42.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "freelance-luxury",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Tag an Image - local =====\n",
      "== OutPut ==\n",
      "\t'outdoor' with confidence 99.93% and with hints of None\n",
      "\t'tree' with confidence 99.87% and with hints of None\n",
      "\t'sky' with confidence 99.00% and with hints of None\n",
      "\t'ground' with confidence 96.23% and with hints of None\n",
      "\t'playground' with confidence 83.61% and with hints of None\n",
      "\t'plant' with confidence 66.10% and with hints of None\n",
      "== MetaData ==\n",
      "\tWidth: 640\n",
      "\tHeight: 640\n",
      "\tFormat: Jpeg\n",
      "\tRequest ID: b20913d4-d40f-4f20-a585-6729588bd2f7\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Tag an Image - local =====\")\n",
    "# Open local image file\n",
    "local_image = open(local_image_path, \"rb\")\n",
    "# Call API local image\n",
    "tags_result_local = computervision_client.tag_image_in_stream(local_image)\n",
    "print(\"== OutPut ==\")\n",
    "for tag in tags_result_local.tags:\n",
    "    print(\"\\t'{}' with confidence {:.2f}% and with hints of {}\".format(tag.name, tag.confidence * 100, tag.hint))\n",
    "print(\"== MetaData ==\")\n",
    "print(\"\\tWidth: \"+str(tags_result_local.metadata.width))\n",
    "print(\"\\tHeight: \"+str(tags_result_local.metadata.height))\n",
    "print(\"\\tFormat: \"+tags_result_local.metadata.format)\n",
    "print(\"\\tRequest ID: \"+tags_result_local.request_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ethical-bridges",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Describe an Image - local =====\n",
      "== Description ==\n",
      "\t'a brick walkway with trees and grass' with confidence 27.36%\n",
      "== TAGS ==\n",
      "\tTags: outdoor\n",
      "\tTags: tree\n",
      "\tTags: sky\n",
      "\tTags: ground\n",
      "REQUEST ID: ccc0d7b7-4d3a-4be5-aa27-eac0b5d460f4\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Describe an Image - local =====\")\n",
    "# Open local image file\n",
    "local_image = open(local_image_path, \"rb\")\n",
    "# Call API\n",
    "description_result = computervision_client.describe_image_in_stream(local_image)\n",
    "\n",
    "# Get the captions (descriptions) from the response, with confidence level\n",
    "print(\"== Description ==\")\n",
    "if (len(description_result.captions) == 0):\n",
    "    print(\"No description detected.\")\n",
    "else:\n",
    "    for caption in description_result.captions:\n",
    "        print(\"\\t'{}' with confidence {:.2f}%\".format(caption.text, caption.confidence * 100))\n",
    "print(\"== TAGS ==\")\n",
    "for i in description_result.tags:\n",
    "    print(\"\\tTags: {}\".format(i))\n",
    "print(\"REQUEST ID: {}\".format(description_result.request_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "located-producer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Detect Objects - local =====\n",
      "Detecting objects in local image:\n",
      "No objects detected.\n",
      "REQUEST ID: e050510d-aa85-424e-9349-d0c26f58f980\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Detect Objects - local\n",
    "This example detects different kinds of objects with bounding boxes in a local image.\n",
    "'''\n",
    "print(\"===== Detect Objects - local =====\")\n",
    "# Get local image with different objects in it\n",
    "local_image_path_objects = local_image_path\n",
    "local_image_objects = open(local_image_path_objects, \"rb\")\n",
    "# Call API with local image\n",
    "detect_objects_results_local = computervision_client.detect_objects_in_stream(local_image_objects)\n",
    "\n",
    "# Print results of detection with bounding boxes\n",
    "print(\"Detecting objects in local image:\")\n",
    "if len(detect_objects_results_local.objects) == 0:\n",
    "    print(\"No objects detected.\")\n",
    "else:\n",
    "    for object in detect_objects_results_local.objects:\n",
    "        print(\"object at location {}, {}, {}, {}\".format( \\\n",
    "        object.rectangle.x, object.rectangle.x + object.rectangle.w, \\\n",
    "        object.rectangle.y, object.rectangle.y + object.rectangle.h))\n",
    "print(\"REQUEST ID: {}\".format(detect_objects_results_local.request_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "simplified-hanging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Area of Intreast for Image =====\n",
      "Area (X,Y,W,H): 0,0,640,640\n",
      "REQUEST ID: b6dee04c-8483-444d-aef0-72becdaef61a\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Area of Intreast for Image =====\")\n",
    "# Open local image file\n",
    "local_image = open(local_image_path, \"rb\")\n",
    "area_interest = computervision_client.get_area_of_interest_in_stream(local_image)\n",
    "\n",
    "print(\"Area (X,Y,W,H): {},{},{},{}\".format(area_interest.area_of_interest.x, area_interest.area_of_interest.y, \n",
    "                                           area_interest.area_of_interest.w, area_interest.area_of_interest.h))\n",
    "print(\"REQUEST ID: {}\".format(area_interest.request_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "becoming-prototype",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Analysis Image =====\n",
      "Categories from local image: \n",
      "\tCatogory: outdoor_road == Score: 0.30078125\n",
      "REQUEST ID: f1493cb9-7282-4711-948f-e87c6b869cf3\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Analysis Image =====\")\n",
    "# Open local image file\n",
    "local_image = open(local_image_path, \"rb\")\n",
    "# Call API\n",
    "categorize_results_local = computervision_client.analyze_image_in_stream(local_image)\n",
    "# Print category results with confidence score\n",
    "print(\"Categories from local image: \")\n",
    "for i in categorize_results_local.categories:\n",
    "    print(\"\\tCatogory: {} == Score: {}\".format(i.name, i.score))\n",
    "    if i.detail != None:\n",
    "        for j in i.detail:\n",
    "            print(j)\n",
    "            for r in j.celebrities:\n",
    "                print(\"\\t\\tCelebrity: {} == Score: {}\".format(r.name, r.confidence))\n",
    "                print(\"Face rectangle\")\n",
    "            for r in j.landmarks:\n",
    "                print(\"\\t\\tLandMark: {} == Score: {}\".format(r.name, r.confidence))\n",
    "                print(\"Face rectangle\")\n",
    "print(\"REQUEST ID: {}\".format(categorize_results_local.request_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-mirror",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-album",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
