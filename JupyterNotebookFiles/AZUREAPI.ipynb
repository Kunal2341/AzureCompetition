{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "blank-magazine",
   "metadata": {},
   "source": [
    "# Calling the API\n",
    "Done:\n",
    "- tag_image_in_stream\n",
    "- describe_image_in_stream\n",
    "- detect_objects_in_stream\n",
    "- get_area_of_interest_in_stream\n",
    "- analyze_image_in_stream\n",
    "\n",
    "https://docs.microsoft.com/en-us/python/api/azure-cognitiveservices-vision-computervision/azure.cognitiveservices.vision.computervision.operations.computervisionclientoperationsmixin?view=azure-python#analyze-image-in-stream-image--visual-features-none--details-none--language--en---description-exclude-none--custom-headers-none--raw-false--callback-none----operation-config-\n",
    "\n",
    "\n",
    "https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/category-taxonomy\n",
    "\n",
    "\n",
    "https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/concept-object-detection\n",
    "\n",
    "https://docs.microsoft.com/en-us/python/api/azure-cognitiveservices-vision-computervision/azure.cognitiveservices.vision.computervision.operations.computervisionclientoperationsmixin?view=azure-python#analyze-image-by-domain-in-stream-model--image--language--en---custom-headers-none--raw-false--callback-none----operation-config-\n",
    "\n",
    "\n",
    "https://azure.microsoft.com/en-us/services/cognitive-services/computer-vision/#features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "authorized-rouge",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "from array import array\n",
    "import os\n",
    "from PIL import Image\n",
    "import sys\n",
    "import time\n",
    "subscription_key = \"<Removed>\"\n",
    "endpoint = \"https://azurehackforaccessibility.cognitiveservices.azure.com/\"\n",
    "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))\n",
    "local_image_path = \"/Users/kunal/Documents/AzureCompetition/Testing_img_NEW290_.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "freelance-luxury",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Tag an Image - local =====\n",
      "== OutPut ==\n",
      "\t'outdoor' with confidence 99.94% and with hints of None\n",
      "\t'sky' with confidence 99.91% and with hints of None\n",
      "\t'tree' with confidence 99.47% and with hints of None\n",
      "\t'way' with confidence 94.48% and with hints of None\n",
      "\t'scene' with confidence 89.64% and with hints of None\n",
      "\t'plant' with confidence 72.12% and with hints of None\n",
      "\t'road' with confidence 63.33% and with hints of None\n",
      "\t'highway' with confidence 18.62% and with hints of None\n",
      "== MetaData ==\n",
      "\tWidth: 640\n",
      "\tHeight: 640\n",
      "\tFormat: Jpeg\n",
      "\tRequest ID: 34191ee5-22e8-43b3-9e9f-60e78f5d12a8\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Tag an Image - local =====\")\n",
    "# Open local image file\n",
    "local_image = open(local_image_path, \"rb\")\n",
    "# Call API local image\n",
    "tags_result_local = computervision_client.tag_image_in_stream(local_image)\n",
    "print(\"== OutPut ==\")\n",
    "for tag in tags_result_local.tags:\n",
    "    print(\"\\t'{}' with confidence {:.2f}% and with hints of {}\".format(tag.name, tag.confidence * 100, tag.hint))\n",
    "print(\"== MetaData ==\")\n",
    "print(\"\\tWidth: \"+str(tags_result_local.metadata.width))\n",
    "print(\"\\tHeight: \"+str(tags_result_local.metadata.height))\n",
    "print(\"\\tFormat: \"+tags_result_local.metadata.format)\n",
    "print(\"\\tRequest ID: \"+tags_result_local.request_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ethical-bridges",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Describe an Image - local =====\n",
      "== Description ==\n",
      "\t'a road with trees and buildings' with confidence 32.45%\n",
      "== TAGS ==\n",
      "\tTags: outdoor\n",
      "\tTags: sky\n",
      "\tTags: tree\n",
      "\tTags: way\n",
      "\tTags: scene\n",
      "\tTags: road\n",
      "\tTags: highway\n",
      "REQUEST ID: 4bc0e44c-1030-49da-93f8-6eeb9b3038de\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Describe an Image - local =====\")\n",
    "# Open local image file\n",
    "local_image = open(local_image_path, \"rb\")\n",
    "# Call API\n",
    "description_result = computervision_client.describe_image_in_stream(local_image)\n",
    "\n",
    "# Get the captions (descriptions) from the response, with confidence level\n",
    "print(\"== Description ==\")\n",
    "if (len(description_result.captions) == 0):\n",
    "    print(\"No description detected.\")\n",
    "else:\n",
    "    for caption in description_result.captions:\n",
    "        print(\"\\t'{}' with confidence {:.2f}%\".format(caption.text, caption.confidence * 100))\n",
    "print(\"== TAGS ==\")\n",
    "for i in description_result.tags:\n",
    "    print(\"\\tTags: {}\".format(i))\n",
    "print(\"REQUEST ID: {}\".format(description_result.request_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-recognition",
   "metadata": {},
   "outputs": [],
   "source": [
    "curl -H \"Ocp-Apim-Subscription-Key: 53f32bba50f1443cb9ae7e927441db83\" -H \"Content-Type: application/json\" \"https://azurehackforaccessibility.cognitiveservices.azure.com/vision/v3.1/analyze?visualFeatures=Categories,Description&details=Landmarks\" -d \"{\\\"url\\\":\\\"https://raw.githubusercontent.com/Kunal2341/testDeleteBS/main/Testing_img_NEW290_.jpg\\\"}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-timothy",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"https://azurehackforaccessibility.cognitiveservices.azure.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "accessible-stability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outdoor\n",
      "sky\n",
      "tree\n",
      "way\n",
      "scene\n",
      "road\n",
      "highway\n"
     ]
    }
   ],
   "source": [
    "for i in description_result.tags:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-fluid",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "located-producer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Detect Objects - local =====\n",
      "Detecting objects in local image:\n",
      "No objects detected.\n",
      "REQUEST ID: bb3e4bbd-c50c-4e0d-9b89-df00e7a92ac2\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Detect Objects - local\n",
    "This example detects different kinds of objects with bounding boxes in a local image.\n",
    "'''\n",
    "print(\"===== Detect Objects - local =====\")\n",
    "# Get local image with different objects in it\n",
    "local_image_path_objects = local_image_path\n",
    "local_image_objects = open(local_image_path_objects, \"rb\")\n",
    "# Call API with local image\n",
    "detect_objects_results_local = computervision_client.detect_objects_in_stream(local_image_objects)\n",
    "\n",
    "# Print results of detection with bounding boxes\n",
    "print(\"Detecting objects in local image:\")\n",
    "if len(detect_objects_results_local.objects) == 0:\n",
    "    print(\"No objects detected.\")\n",
    "else:\n",
    "    for object in detect_objects_results_local.objects:\n",
    "        print(\"object at location {}, {}, {}, {}\".format( \\\n",
    "        object.rectangle.x, object.rectangle.x + object.rectangle.w, \\\n",
    "        object.rectangle.y, object.rectangle.y + object.rectangle.h))\n",
    "print(\"REQUEST ID: {}\".format(detect_objects_results_local.request_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "simplified-hanging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Area of Intreast for Image =====\n",
      "Area (X,Y,W,H): 0,0,640,640\n",
      "REQUEST ID: 1fe7c387-6fbe-45a9-8d72-830c89e65c69\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Area of Intreast for Image =====\")\n",
    "# Open local image file\n",
    "local_image = open(local_image_path, \"rb\")\n",
    "area_interest = computervision_client.get_area_of_interest_in_stream(local_image)\n",
    "\n",
    "print(\"Area (X,Y,W,H): {},{},{},{}\".format(area_interest.area_of_interest.x, area_interest.area_of_interest.y, \n",
    "                                           area_interest.area_of_interest.w, area_interest.area_of_interest.h))\n",
    "print(\"REQUEST ID: {}\".format(area_interest.request_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "becoming-prototype",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Analysis Image =====\n",
      "Categories from local image: \n",
      "\tCatogory: outdoor_road == Score: 0.5703125\n",
      "REQUEST ID: 68f404fc-c496-4211-bf30-bb494e87de11\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Analysis Image =====\")\n",
    "# Open local image file\n",
    "local_image = open(local_image_path, \"rb\")\n",
    "# Call API\n",
    "categorize_results_local = computervision_client.analyze_image_in_stream(local_image)\n",
    "# Print category results with confidence score\n",
    "print(\"Categories from local image: \")\n",
    "for i in categorize_results_local.categories:\n",
    "    print(\"\\tCatogory: {} == Score: {}\".format(i.name, i.score))\n",
    "    if i.detail != None:\n",
    "        for j in i.detail:\n",
    "            print(j)\n",
    "            for r in j.celebrities:\n",
    "                print(\"\\t\\tCelebrity: {} == Score: {}\".format(r.name, r.confidence))\n",
    "                print(\"Face rectangle\")\n",
    "            for r in j.landmarks:\n",
    "                print(\"\\t\\tLandMark: {} == Score: {}\".format(r.name, r.confidence))\n",
    "                print(\"Face rectangle\")\n",
    "print(\"REQUEST ID: {}\".format(categorize_results_local.request_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-mirror",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-album",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
